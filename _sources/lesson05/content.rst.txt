Lesson 05: Neural Networks as Code
**********************************

Learning Objectives
===================

**To be updated**

* A perceptron takes multiple inputs, multiplies each by a weight value and sums the weighted inputs. It then applies an activation function to the sum.
* Multiple perceptrons can be combined to form a neural network which can solve functions that arenâ€™t linearly separable.
* We can train a whole neural network with the back propagation algorithm. Scikit-learn includes an implementation of this algorithm.
* Training a neural network requires some training data to show the network examples of what to learn.
* To validate our training we split the the training data into a training set and a test set.
* To ensure the whole dataset can be used in training and testing we can train multiple times with different subsets of the data acting as training/testing data. This is called cross validation.


Content
=======

This lesson is based on `Neural Networks <https://carpentries-incubator.github.io/machine-learning-novice-sklearn/05-neural-networks/index.html>`_ and will be shared as a video.

The content should start with the heading **Multi Layer Perceptrons** directly.

Check your Learning
===================

.. admonition:: Exercise 1

   **TBA**

   1. ???
   2. ???
   3. ???
   4. ???


Exercises
=========

* through OpenML https://docs.openml.org/Datasets/
   * https://sci2s.ugr.es/keel/datasets.php
   * https://archive.ics.uci.edu/ml/datasets.php?format=&task=cla&att=&area=&numAtt=&numIns=&type=&sort=nameUp&view=table

