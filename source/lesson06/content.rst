Lesson 06: How did we train
***************************

Learning Objectives
===================

**To be updated, content might spill into lesson 07**

- list/repeat the three ingredients to a feed forward network: input, hidden layers, output

- describe training with mini-batched based weight-update rule

- describe a softmax layer
- motivate the loss function of categorical crossentropy

- define backpropagation
- calculate example backpropagation


Content
=======

based on discussion in `Mathematics for Machine Learning` book

Check your Learning
===================

.. admonition:: Exercise 1

   **TBA**

   1. ???
   2. ???
   3. ???
   4. ???


Exercises
=========

* through `OpenML <https://docs.openml.org/Datasets/>`_ or `keras datasets <https://keras.io/api/datasets/>`_
   * https://sci2s.ugr.es/keel/datasets.php
   * https://archive.ics.uci.edu/ml/datasets.php?format=&task=cla&att=&area=&numAtt=&numIns=&type=&sort=nameUp&view=table

